{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCZIUVDwzG0d6ziQ+HMp45",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/B-MEbrahim/Torch/blob/main/DLwPT/ch_6/dlwpt_ch6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v9U6AneFxGbk"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "t_c = torch.tensor(t_c).unsqueeze(1) # <1>\n",
        "t_u = torch.tensor(t_u).unsqueeze(1) # <1>\n",
        "\n",
        "t_u.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPklQziI2n68",
        "outputId": "030ac5d2-2072-4ce5-de0a-367fe19fdcc5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "\n",
        "train_indices, val_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqLah7Sc2ryi",
        "outputId": "3548b204-e1e5-4226-ddcf-20ab9cf701d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 7,  9,  3,  5, 10,  6,  0,  8,  1]), tensor([2, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_u_train = t_u[train_indices]\n",
        "t_c_train = t_c[train_indices]\n",
        "\n",
        "t_u_val = t_u[val_indices]\n",
        "t_c_val = t_c[val_indices]\n",
        "\n",
        "t_un_train = 0.1 * t_u_train\n",
        "t_un_val = 0.1 * t_u_val"
      ],
      "metadata": {
        "id": "yC407pbV2wRC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "linear_model = nn.Linear(1, 1)\n",
        "linear_model(t_un_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1LKbvyU2xo-",
        "outputId": "836e0d34-70b2-4ddb-c1e8-330baf8f1b66"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5858],\n",
              "        [1.5084]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHoYDA032731",
        "outputId": "91f7c43d-9adb-4a88-d761-4697c6042792"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.4074]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjjDa4Q23gmi",
        "outputId": "77949c0b-4e0b-49aa-faaf-2717df46a585"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.7855], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(1)\n",
        "linear_model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul_tK-8-3iAt",
        "outputId": "41727b92-81b6-4105-8304-35bfd07b2a96"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.3780], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(10, 1)\n",
        "linear_model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPQEXJti3rjt",
        "outputId": "a34afaad-2220-46ac-dd65-8bb4e29ac191"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3780],\n",
              "        [-0.3780],\n",
              "        [-0.3780],\n",
              "        [-0.3780],\n",
              "        [-0.3780],\n",
              "        [-0.3780],\n",
              "        [-0.3780],\n",
              "        [-0.3780],\n",
              "        [-0.3780],\n",
              "        [-0.3780]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = nn.Linear(1, 1)\n",
        "optimizer = optim.SGD(\n",
        "    linear_model.parameters(),\n",
        "    lr=1e-2\n",
        ")"
      ],
      "metadata": {
        "id": "Yu3xfM_X38_X"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "0EOJMxh74s_g",
        "outputId": "0ca38c1e-f207-4821-d026-ce71248dd7d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Linear(in_features=1, out_features=1, bias=True)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.nn.modules.module.Module.parameters</b><br/>def parameters(recurse: bool=True) -&gt; Iterator[Parameter]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py</a>Return an iterator over module parameters.\n",
              "\n",
              "This is typically passed to an optimizer.\n",
              "\n",
              "Args:\n",
              "    recurse (bool): if True, then yields parameters of this module\n",
              "        and all submodules. Otherwise, yields only parameters that\n",
              "        are direct members of this module.\n",
              "\n",
              "Yields:\n",
              "    Parameter: module parameter\n",
              "\n",
              "Example::\n",
              "\n",
              "    &gt;&gt;&gt; # xdoctest: +SKIP(&quot;undefined vars&quot;)\n",
              "    &gt;&gt;&gt; for param in model.parameters():\n",
              "    &gt;&gt;&gt;     print(type(param), param.size())\n",
              "    &lt;class &#x27;torch.Tensor&#x27;&gt; (20L,)\n",
              "    &lt;class &#x27;torch.Tensor&#x27;&gt; (20L, 1L, 5L, 5L)</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 2656);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(linear_model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOz1GGfa4vRR",
        "outputId": "999b1b23-416b-4960-8a19-10827427db75"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[0.3962]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.4467], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, model, loss_fn,\n",
        "                  t_u_train, t_u_val,\n",
        "                  t_c_train, t_c_val):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    t_p_train = model(t_u_train)\n",
        "    loss_train = loss_fn(t_p_train, t_c_train)\n",
        "\n",
        "    t_p_val = model(t_u_val)\n",
        "    loss_val = loss_fn(t_p_val, t_c_val)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch == 1 or epoch % 1000 == 0:\n",
        "      print(f\"Epoch {epoch}, Trainging loss {loss_train}:.4f\",\n",
        "            f\"Validation loss {loss_val}:.4f\")\n",
        ""
      ],
      "metadata": {
        "id": "OuR5ptU343Bb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(t_p, t_c):\n",
        "  squared_diff = (t_p - t_c) ** 2\n",
        "  return squared_diff.mean()\n",
        "\n",
        "linear_model = nn.Linear(1, 1)\n",
        "optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs=3000,\n",
        "    optimizer=optimizer,\n",
        "    model=linear_model,\n",
        "    loss_fn=loss_fn,\n",
        "    t_u_train=t_un_train,\n",
        "    t_u_val=t_un_val,\n",
        "    t_c_train=t_c_train,\n",
        "    t_c_val=t_c_val\n",
        ")\n",
        "print()\n",
        "print(linear_model.weight)\n",
        "print(linear_model.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7Mp3uKC6GHP",
        "outputId": "fd34bb9b-5011-4a11-f888-e0e7463b8b39"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Trainging loss 185.51113891601562:.4f Validation loss 166.30963134765625:.4f\n",
            "Epoch 1000, Trainging loss 3.5776007175445557:.4f Validation loss 2.5763092041015625:.4f\n",
            "Epoch 2000, Trainging loss 3.043879508972168:.4f Validation loss 2.504833936691284:.4f\n",
            "Epoch 3000, Trainging loss 3.0354928970336914:.4f Validation loss 2.4961354732513428:.4f\n",
            "\n",
            "Parameter containing:\n",
            "tensor([[5.3717]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-17.2269], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_model = nn.Sequential(\n",
        "    nn.Linear(1, 13),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(13, 1)\n",
        ")\n",
        "seq_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdgHwVOp68ma",
        "outputId": "90350f33-1dbd-4a55-9a92-8bb145954740"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1, out_features=13, bias=True)\n",
              "  (1): Tanh()\n",
              "  (2): Linear(in_features=13, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in seq_model.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ld9gg9I7wxx",
        "outputId": "9da23b4c-87b9-4820-fd28-f2719c086f68"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.weight torch.Size([13, 1])\n",
            "0.bias torch.Size([13])\n",
            "2.weight torch.Size([1, 13])\n",
            "2.bias torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "seq_model = nn.Sequential(OrderedDict([\n",
        "    ('hidden_linear', nn.Linear(1, 8)),\n",
        "    ('hidden_activation', nn.Tanh()),\n",
        "    ('output_linear', nn.Linear(8, 1))\n",
        "]))\n",
        "seq_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m09FX8Ng8JXr",
        "outputId": "5e5a2de6-24b8-4427-ad9b-65a01d0f691d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (hidden_linear): Linear(in_features=1, out_features=8, bias=True)\n",
              "  (hidden_activation): Tanh()\n",
              "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in seq_model.named_parameters():\n",
        "    print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vblz03tI8qp9",
        "outputId": "d4055310-92e5-4219-fa79-2d75fc1e042a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_linear.weight torch.Size([8, 1])\n",
            "hidden_linear.bias torch.Size([8])\n",
            "output_linear.weight torch.Size([1, 8])\n",
            "output_linear.bias torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(seq_model.parameters(), lr=1e-3) # <1>\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = optimizer,\n",
        "    model = seq_model,\n",
        "    loss_fn = nn.MSELoss(),\n",
        "    t_u_train = t_un_train,\n",
        "    t_u_val = t_un_val,\n",
        "    t_c_train = t_c_train,\n",
        "    t_c_val = t_c_val)\n",
        "\n",
        "print('output', seq_model(t_un_val))\n",
        "print('answer', t_c_val)\n",
        "print('hidden', seq_model.hidden_linear.weight.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPnd3RZn83Wa",
        "outputId": "a8a37b55-0444-4735-bbcc-d1c3d342c315"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Trainging loss 176.8362579345703:.4f Validation loss 154.4783935546875:.4f\n",
            "Epoch 1000, Trainging loss 4.506984233856201:.4f Validation loss 2.368572235107422:.4f\n",
            "Epoch 2000, Trainging loss 2.3652288913726807:.4f Validation loss 1.837519645690918:.4f\n",
            "Epoch 3000, Trainging loss 2.14286470413208:.4f Validation loss 2.118964195251465:.4f\n",
            "Epoch 4000, Trainging loss 1.9180965423583984:.4f Validation loss 2.0727312564849854:.4f\n",
            "Epoch 5000, Trainging loss 1.8419020175933838:.4f Validation loss 2.09771990776062:.4f\n",
            "output tensor([[13.4970],\n",
            "        [12.2204]], grad_fn=<AddmmBackward0>)\n",
            "answer tensor([[15.],\n",
            "        [11.]])\n",
            "hidden tensor([[-1.4214e-03],\n",
            "        [ 1.3251e+00],\n",
            "        [-3.9169e+00],\n",
            "        [-1.2754e-02],\n",
            "        [ 4.2699e-01],\n",
            "        [ 4.3675e+00],\n",
            "        [ 2.0510e-01],\n",
            "        [ 4.4466e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AQtV6iyu9WmM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}